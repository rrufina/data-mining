{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from utils import *\n",
    "from orderbook import OrderBook\n",
    "from features import FeatureGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_orderbooks(order_log: list):\n",
    "    \"\"\"\n",
    "    Function for making orderbooks for each spectrum\n",
    "    \n",
    "    Return orderbooks, dataframe with spectrums and dataframe with VWAPs\n",
    "    \"\"\"\n",
    "    # creating order book for each seccode\n",
    "    order_books = dict()\n",
    "    for secc in feature_seccodes:\n",
    "        order_books[secc] = OrderBook(secc)\n",
    "\n",
    "    # creating spectrum for each seccode\n",
    "    spectrums = dict()\n",
    "    for secc in feature_seccodes:\n",
    "        spectrums[secc] = FeatureGenerator(seccode=secc, px_step=instruments_info[secc]['PRICE_STEP'])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    list_spec = []\n",
    "    list_vwap = []\n",
    "    list_bid_ask_spread = []\n",
    "    \n",
    "    col_names = ['SECCODE', 'TIMESTAMP', 'BID_ASK']\n",
    "    feature_names = ['SECCODE', 'TIMESTAMP', 'BID', 'ASK']\n",
    "    bid_ask_spread_names = ['SECCODE', 'TIMESTAMP', 'SPREAD']\n",
    "\n",
    "    for row_log in order_log:\n",
    "        if instruments_info[row_log['SECCODE']]['SCHEDULE'] <= row_log['TIME']:\n",
    "            continue\n",
    "\n",
    "        is_ask = row_log['BUYSELL'] == 'S'\n",
    "\n",
    "        order_book = order_books[row_log['SECCODE']]\n",
    "        spectrum = spectrums[row_log['SECCODE']]\n",
    "\n",
    "        # handle post\n",
    "        if row_log['ACTION'] == Action.POST:\n",
    "            order_book.add_entry(entry=row_log, \n",
    "                                 ask=is_ask)\n",
    "            spectrum.update_post(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "\n",
    "        # handle revoke\n",
    "        elif row_log['ACTION'] == Action.REVOKE:\n",
    "            order_book.revoke(orderno=row_log['ORDERNO'], volume=row_log['VOLUME'], \n",
    "                              ask=is_ask, row_numb=row_log['NO'])\n",
    "            spectrum.update_revoke(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "\n",
    "        elif row_log['ACTION'] == Action.MATCH:\n",
    "            order_book.match(orderno=row_log['ORDERNO'], volume=row_log['VOLUME'], \n",
    "                              ask=is_ask, row_numb=row_log['NO'])\n",
    "            spectrum.update_match(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "\n",
    "        # print(order_book.bids, '-----', order_book.asks, '-----', spectrum.best_ask - spectrum.best_bid, '=====', sep='\\n')\n",
    "        \n",
    "        # для каждой новой row считаем спектрум добавляем в df\n",
    "        values = spectrum.bids_normalized.copy()\n",
    "        values.extend(spectrum.asks_normalized.copy())\n",
    "        d_values = [ row_log['SECCODE'], row_log['TIME'], values ]\n",
    "        list_spec.append(d_values)\n",
    "        \n",
    "        # для каждой новой row считаем VWAPs и добавляем в df\n",
    "        vwaps_bids = list(spectrum.VWAP_bids.values()).copy()\n",
    "        vwaps_asks = list(spectrum.VWAP_asks.values()).copy()\n",
    "        d_vwaps = [ row_log['SECCODE'], row_log['TIME'], vwaps_bids, vwaps_asks ]\n",
    "        list_vwap.append(d_vwaps)\n",
    "\n",
    "        # Add bid-ask spread\n",
    "        d_bid_ask_spread = [ row_log['SECCODE'], row_log['TIME'], spectrum.bid_ask_spread ]\n",
    "        list_bid_ask_spread.append(d_bid_ask_spread)\n",
    "    \n",
    "    # Saving spectrum\n",
    "    df_spec = pd.DataFrame(list_spec, columns=col_names)\n",
    "    # Saving VWAPs\n",
    "    df_vwap = pd.DataFrame(list_vwap, columns=feature_names)\n",
    "    # Saving bid-ask spread\n",
    "    df_bid_ask_spread = pd.DataFrame(list_bid_ask_spread, columns=bid_ask_spread_names)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    return order_books, df_spec, df_vwap, df_bid_ask_spread, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading\n",
    "WORKING_DIR = r\"D:\\Data\\MOEX-FX\\2018-03\\\\\"\n",
    "WORKING_DIR = r'D:\\Innopolis University\\2021 Spring Semester\\Data Mining\\data-mining\\\\'\n",
    "\n",
    "orderlog_filename = WORKING_DIR + 'OrderLog20180330.txt'\n",
    "\n",
    "order_log = read_orderlog(orderlog_filename)\n",
    "\n",
    "# Preprocessing\n",
    "order_log = filter(order_log, lambda row: row['SECCODE'] in feature_seccodes)\n",
    "order_log = preprocess_orderlog(order_log)\n",
    "\n",
    "# Make orderbooks, spectrum, and vwaps\n",
    "order_books, df_spec, df_vwap, df_spread, exec_time = make_orderbooks(order_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrums(moex_dir: str, months: list, save_dir: str) -> None:\n",
    "    spectrums_dir = os.path.join(save_dir, 'spectrums')\n",
    "    try:\n",
    "        os.mkdir(spectrums_dir)\n",
    "    except Exception:\n",
    "        print(f\"{spectrums_dir} dir already exists. It may be overwritten.\")\n",
    "    \n",
    "    \n",
    "    for month in months:\n",
    "        working_dir = os.path.join(moex_dir, month)\n",
    "        save_to = os.path.join(spectrums_dir, month)\n",
    "        try:\n",
    "            os.mkdir(save_to)\n",
    "        except Exception:\n",
    "            print(f\"{save_to} dir already exists. It may be overwritten.\")\n",
    "        \n",
    "        print(f\"processing {month}\")\n",
    "        for filename in os.listdir(working_dir):\n",
    "            # acquiring orderlog\n",
    "            if 'orderlog' in filename.lower():\n",
    "                print(f\"processing {filename}\")\n",
    "                # reading it\n",
    "                orderlog_path = os.path.join(working_dir, filename)\n",
    "                order_log = read_orderlog(orderlog_path)\n",
    "                # preprocessing\n",
    "                order_log = filter(order_log, lambda row: row['SECCODE'] in feature_seccodes)\n",
    "                order_log = preprocess_orderlog(order_log)\n",
    "                \n",
    "                # creating order book for each seccode\n",
    "                order_books = dict()\n",
    "                for secc in feature_seccodes:\n",
    "                    order_books[secc] = OrderBook(secc)\n",
    "\n",
    "                # creating spectrum for each seccode\n",
    "                spectrums = dict()\n",
    "                for secc in feature_seccodes:\n",
    "                    spectrums[secc] = FeatureGenerator(seccode=secc, px_step=instruments_info[secc]['PRICE_STEP'])\n",
    "                    \n",
    "                _, df_spec, df_vwap, df_spread, exec_time = make_orderbooks(order_log)\n",
    "                \n",
    "                # saving spectrum\n",
    "                for secc in feature_seccodes:\n",
    "                    save_name = filename.lower().replace('orderlog', 'tradelog')[:-4] + '_' + secc + '.csv'\n",
    "                    df_cur = df_spec[df_spec['SECCODE'] == secc].sort_values(by=['TIMESTAMP'])\n",
    "                    df_cur.to_csv(os.path.join(save_to, save_name))\n",
    "                    df_cur = None\n",
    "                    \n",
    "                    save_name = filename.lower().replace('orderlog', 'vwap')[:-4] + '_' + secc + '.csv'\n",
    "                    df_cur = df_vwap[df_vwap['SECCODE'] == secc].sort_values(by=['TIMESTAMP'])\n",
    "                    df_cur.to_csv(os.path.join(save_to, save_name))\n",
    "                    df_cur = None\n",
    "                    \n",
    "                    save_name = filename.lower().replace('orderlog', 'spread')[:-4] + '_' + secc + '.csv'\n",
    "                    df_cur = df_spread[df_spread['SECCODE'] == secc].sort_values(by=['TIMESTAMP'])\n",
    "                    df_cur.to_csv(os.path.join(save_to, save_name))\n",
    "                    df_cur = None\n",
    "                \n",
    "                order_log = None\n",
    "                order_books = None\n",
    "                spectrums = None\n",
    "                df_spec = None\n",
    "                \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\spectrums dir already exists. It may be overwritten.\n",
      ".\\spectrums\\2018-03 dir already exists. It may be overwritten.\n",
      "processing 2018-03\n",
      "processing OrderLog20180301.txt\n",
      "processing OrderLog20180302.txt\n",
      "processing OrderLog20180305.txt\n",
      "processing OrderLog20180306.txt\n",
      "processing OrderLog20180307.txt\n",
      "processing OrderLog20180309.txt\n",
      "processing OrderLog20180312.txt\n",
      "processing OrderLog20180313.txt\n",
      "processing OrderLog20180314.txt\n",
      "processing OrderLog20180315.txt\n",
      "processing OrderLog20180316.txt\n",
      "processing OrderLog20180319.txt\n",
      "processing OrderLog20180320.txt\n",
      "processing OrderLog20180321.txt\n",
      "processing OrderLog20180322.txt\n",
      "processing OrderLog20180323.txt\n",
      "processing OrderLog20180326.txt\n",
      "processing OrderLog20180327.txt\n",
      "processing OrderLog20180328.txt\n",
      "processing OrderLog20180329.txt\n",
      "processing OrderLog20180330.txt\n",
      "\n",
      "\n",
      "processing 2018-04\n",
      "processing OrderLog20180402.txt\n",
      "processing OrderLog20180403.txt\n",
      "processing OrderLog20180404.txt\n",
      "processing OrderLog20180405.txt\n",
      "processing OrderLog20180406.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c732f309048e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate_spectrums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoex_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"D:\\Downloads\\data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2018-03'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2018-04'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2018-03'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-1117c943b959>\u001b[0m in \u001b[0;36mgenerate_spectrums\u001b[1;34m(moex_dir, months, save_dir)\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0msave_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'orderlog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tradelog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msecc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mdf_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_spec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_spec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECCODE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msecc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TIMESTAMP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     \u001b[0mdf_cur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                     \u001b[0mdf_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n\u001b[1;32m--> 315\u001b[1;33m                                   self.cols, self.writer)\n\u001b[0m",
      "\u001b[1;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_spectrums(moex_dir=r\"D:\\Downloads\\data\", months=['2018-03', '2018-04', '2018-03'], save_dir='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
