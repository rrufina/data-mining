{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from utils import *\n",
    "from orderbook import OrderBook\n",
    "from spectrum import Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_orderbooks(order_log: list, do_spec: bool):\n",
    "    \"\"\"\n",
    "    function for making orderbooks for each spectrum\n",
    "    \n",
    "    return orderbooks and dataframe with spectrums if do_spec is true\n",
    "    otherwise, returns just orderbooks\n",
    "    \"\"\"\n",
    "    # creating order book for each seccode\n",
    "    order_books = dict()\n",
    "    for secc in SECCODES:\n",
    "        order_books[secc] = OrderBook(secc)\n",
    "\n",
    "    # creating spectrum for each seccode\n",
    "    spectrums = dict()\n",
    "    for secc in SECCODES:\n",
    "        spectrums[secc] = Spectrum(seccode=secc)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    k = 0\n",
    "    list_spec = []\n",
    "    col_names = ['SECCODE', 'TIMESTAMP', 'BID_ASK']\n",
    "\n",
    "\n",
    "    for row_log in order_log:\n",
    "        if instruments_info[row_log['SECCODE']]['SCHEDULE'] <= row_log['TIME']:\n",
    "            continue\n",
    "\n",
    "        is_ask = row_log['BUYSELL'] == 'S'\n",
    "\n",
    "        order_book = order_books[row_log['SECCODE']]\n",
    "        spectrum = spectrums[row_log['SECCODE']]\n",
    "        correct = False\n",
    "        \n",
    "        # CATCHING AGGRESSORS\n",
    "        if row_log['PRICE'] == 0:\n",
    "            continue\n",
    "        if is_ask:\n",
    "            if spectrum.best_bid > 0 and row_log['PRICE'] <= spectrum.best_bid:\n",
    "                continue\n",
    "        else:\n",
    "            if spectrum.best_ask < 1e19 and row_log['PRICE'] >= spectrum.best_ask:\n",
    "                continue\n",
    "\n",
    "        # handle post\n",
    "        if row_log['ACTION'] == Action.POST:\n",
    "            order_book.add_entry(entry=row_log, \n",
    "                                 ask=is_ask)\n",
    "            if do_spec:\n",
    "                spectrum.update_post(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "                \n",
    "            correct = True\n",
    "\n",
    "        # handle revoke\n",
    "        elif row_log['ACTION'] == Action.REVOKE:\n",
    "            correct = order_book.revoke(orderno=row_log['ORDERNO'], volume=row_log['VOLUME'], \n",
    "                              ask=is_ask, row_numb=row_log['NO'])\n",
    "            if do_spec and correct:\n",
    "                spectrum.update_revoke(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "\n",
    "        elif row_log['ACTION'] == Action.MATCH:\n",
    "            correct = order_book.match(orderno=row_log['ORDERNO'], volume=row_log['VOLUME'], \n",
    "                              ask=is_ask, row_numb=row_log['NO'])\n",
    "            if do_spec and correct:\n",
    "                spectrum.update_match(order_book=order_book, new_price=row_log['PRICE'], \n",
    "                                 volume=row_log['VOLUME'], ask=is_ask)\n",
    "\n",
    "\n",
    "        if do_spec and correct:\n",
    "\n",
    "            # для каждой новой row считаем спектрум и добавляем в файлик\n",
    "            values = spectrum.bids_normalized.copy()\n",
    "            values.extend(spectrum.asks_normalized.copy())\n",
    "            d = [ row_log['SECCODE'], row_log['TIME'], values ]\n",
    "            list_spec.append(d)\n",
    "        #     k += 1\n",
    "        #     if k == 1000:\n",
    "        #         df_spec = pd.DataFrame(list_spec, columns=col_names)\n",
    "        #         df_spec.to_csv('spectrums-'+str(k//1000)+'.csv')\n",
    "\n",
    "        # TODO: do spectrum opearation only if no error during order book update\n",
    "    \n",
    "    df_spec = None\n",
    "    if do_spec:\n",
    "        # saving spectrum\n",
    "        df_spec = pd.DataFrame(list_spec, columns=col_names)\n",
    "        \n",
    "    \n",
    "    return order_books, df_spec\n",
    "   \n",
    "                \n",
    "                       \n",
    "\n",
    "def generate_spectrums(moex_dir: str, months: list, save_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    function for generating spectrums\n",
    "    resulting csv files are correclty sorted\n",
    "    \n",
    "    moex_dir - an absolute path to MOEX-FX folder storing months folders\n",
    "    months - a list of month to preprocess for exmaple, ['2018-03', '2018-05']\n",
    "    save_dir - a path to where spectrums should be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    spectrums_dir = os.path.join(save_dir, 'spectrums')\n",
    "    try:\n",
    "        os.mkdir(spectrums_dir)\n",
    "    except Exception:\n",
    "        print(f\"{spectrums_dir} dir already exists. It may be overwritten.\")\n",
    "    \n",
    "    \n",
    "    for month in months:\n",
    "        working_dir = os.path.join(moex_dir, month)\n",
    "        save_to = os.path.join(spectrums_dir, month)\n",
    "        try:\n",
    "            os.mkdir(save_to)\n",
    "        except Exception:\n",
    "            print(f\"{save_to} dir already exists. It may be overwritten.\")\n",
    "        \n",
    "        print(f\"processing {month}\")\n",
    "        for filename in os.listdir(working_dir):\n",
    "            # acquiring orderlog\n",
    "            if 'orderlog' in filename.lower():\n",
    "                print(f\"processing {filename}\")\n",
    "                # reading it\n",
    "                orderlog_path = os.path.join(working_dir, filename)\n",
    "                order_log = read_orderlog(orderlog_path)\n",
    "                # preprocessing\n",
    "                order_log = preprocess_orderlog(order_log)\n",
    "                \n",
    "                # creating order book for each seccode\n",
    "                order_books = dict()\n",
    "                for secc in SECCODES:\n",
    "                    order_books[secc] = OrderBook(secc)\n",
    "\n",
    "                # creating spectrum for each seccode\n",
    "                spectrums = dict()\n",
    "                for secc in SECCODES:\n",
    "                    spectrums[secc] = Spectrum(seccode=secc)\n",
    "                    \n",
    "                _, df_spec = make_orderbooks(order_log, True)\n",
    "                \n",
    "                # saving spectrum\n",
    "                for secc in SECCODES:\n",
    "                    save_name = filename.lower().replace('orderlog', 'spectrum')[:-4] + '_' + secc + '.csv'\n",
    "                    df_cur = df_spec[df_spec['SECCODE'] == secc].sort_values(by=['TIMESTAMP'])\n",
    "                    df_cur.to_csv(os.path.join(save_to, save_name))\n",
    "                    df_cur = None\n",
    "                \n",
    "                order_log = None\n",
    "                order_books = None\n",
    "                spectrums = None\n",
    "                df_spec = None\n",
    "                \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks 1-3 (for a single file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading\n",
    "WORKING_DIR = r\"D:\\Data\\MOEX-FX\\2018-03\\\\\"\n",
    "orderlog_filename = WORKING_DIR + 'OrderLog20180301.txt'\n",
    "order_log = read_orderlog(orderlog_filename)\n",
    "# preprocesiing\n",
    "order_log = preprocess_orderlog(order_log)\n",
    "# making orderbooks and spectrum\n",
    "order_books, df_spec = make_orderbooks(order_log, True)\n",
    "df_spec.to_csv('spectrum_singl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov for a single file with spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999988856337011 0.999999999999995\n",
      "0.9999993639653042 1.0000000000000102\n",
      "0.9999999999999948 0.9999999999999939\n",
      "1.0000000000001537 0.9999999999999998\n",
      "1.0000000000000004 0.9999999999999986\n",
      "0.9999986448433577 0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "from pdfspec import PdfSpec\n",
    "\n",
    "# see tasks 1-3 last line\n",
    "df_spec = pd.read_csv('spectrum_singl.csv')\n",
    "\n",
    "# separating spectrums by their seccodes\n",
    "spectrums_by_seccode = dict()\n",
    "for secc in SECCODES:\n",
    "    spectrums_by_seccode[secc] = df_spec[df_spec['SECCODE'] == secc].copy()\n",
    "    spectrums_by_seccode[secc].sort_values(by=['TIMESTAMP'], inplace=True)\n",
    "\n",
    "# release memory\n",
    "df_spec = None\n",
    "\n",
    "# pdfs of spectrums separated by seccode\n",
    "pdfs_spec = dict()\n",
    "for secc in SECCODES:\n",
    "    pdfs_spec[secc] = PdfSpec(seccode=secc)\n",
    "    \n",
    "# calculating averages\n",
    "for secc in SECCODES:\n",
    "    pdfs_spec[secc].calc_avgs(spectrums_by_seccode[secc])\n",
    "    # just to make sure that sums are approximately equtal to 1\n",
    "    print(sum(pdfs_spec[secc].bids_count), sum(pdfs_spec[secc].asks_time))\n",
    "\n",
    "# release memory\n",
    "spectrums_by_seccode = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing KS-test for USD000000TOD\n",
      "\tbid count vs ask count - pval = 0.7869297884777761\n",
      "\tbid time vs ask time - pval = 0.7869297884777761\n",
      "\tbid time vs bid count - pval = 1.0\n",
      "\task time vs ask count - pval = 1.0\n",
      "Performing KS-test for USD000UTSTOM\n",
      "\tbid count vs ask count - pval = 0.9944575548290717\n",
      "\tbid time vs ask time - pval = 0.9944575548290717\n",
      "\tbid time vs bid count - pval = 1.0\n",
      "\task time vs ask count - pval = 1.0\n",
      "Performing KS-test for EUR_RUB__TOD\n",
      "\tbid count vs ask count - pval = 1.0\n",
      "\tbid time vs ask time - pval = 0.9944575548290717\n",
      "\tbid time vs bid count - pval = 1.0\n",
      "\task time vs ask count - pval = 1.0\n",
      "Performing KS-test for EUR_RUB__TOM\n",
      "\tbid count vs ask count - pval = 0.9944575548290717\n",
      "\tbid time vs ask time - pval = 0.9944575548290717\n",
      "\tbid time vs bid count - pval = 1.0\n",
      "\task time vs ask count - pval = 1.0\n",
      "Performing KS-test for EURUSD000TOD\n",
      "\tbid count vs ask count - pval = 0.00021650176448938054\n",
      "\tbid time vs ask time - pval = 0.00021650176448938054\n",
      "\tbid time vs bid count - pval = 0.012340600575894691\n",
      "\task time vs ask count - pval = 0.7869297884777761\n",
      "Performing KS-test for EURUSD000TOM\n",
      "\tbid count vs ask count - pval = 0.00021650176448938054\n",
      "\tbid time vs ask time - pval = 0.00021650176448938054\n",
      "\tbid time vs bid count - pval = 0.9944575548290717\n",
      "\task time vs ask count - pval = 0.9944575548290717\n"
     ]
    }
   ],
   "source": [
    "for secc in SECCODES:\n",
    "    print(f\"Performing KS-test for {secc}\")\n",
    "    pval = PdfSpec.kstest(pdfs_spec[secc].bids_count,\n",
    "          pdfs_spec[secc].asks_count)\n",
    "    print(f\"\\tbid count vs ask count - pval = {pval}\")\n",
    "    pval = PdfSpec.kstest(pdfs_spec[secc].bids_time,\n",
    "          pdfs_spec[secc].asks_time)\n",
    "    print(f\"\\tbid time vs ask time - pval = {pval}\")\n",
    "    pval = PdfSpec.kstest(pdfs_spec[secc].bids_time,\n",
    "          pdfs_spec[secc].bids_count)\n",
    "    print(f\"\\tbid time vs bid count - pval = {pval}\")\n",
    "    pval = PdfSpec.kstest(pdfs_spec[secc].asks_time,\n",
    "          pdfs_spec[secc].asks_count)\n",
    "    print(f\"\\task time vs ask count - pval = {pval}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to generate spectrums for all days\n",
    "generate_spectrums(moex_dir=r\"D:\\Data\\MOEX-FX\", months=['2018-03', '2018-04', '2018-03'], save_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccesing. Date: 20180301. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180301. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180301. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180302. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180302. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180302. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180305. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180305. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180305. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180306. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180306. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180306. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180307. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180307. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180307. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180309. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180309. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180309. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180312. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180312. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180312. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180313. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180313. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180313. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180314. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180314. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180314. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180315. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180315. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180315. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180316. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180316. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180316. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180319. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180319. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180319. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180320. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180320. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180320. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180321. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180321. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180321. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180322. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180322. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180322. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180323. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180323. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180323. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180326. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180326. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180326. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180327. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180327. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180327. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180328. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180328. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180328. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180329. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180329. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180329. Instrument: USD000UTSTOM\n",
      "\n",
      "Proccesing. Date: 20180330. Instrument: EURUSD000TOM\n",
      "\n",
      "Proccesing. Date: 20180330. Instrument: EUR_RUB__TOM\n",
      "\n",
      "Proccesing. Date: 20180330. Instrument: USD000UTSTOM\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\norderlog_filename = WORKING_DIR + 'OrderLog20180301.txt'\\norder_log = read_orderlog(orderlog_filename)\\n# preprocesiing\\norder_log = preprocess_orderlog(order_log)\\n# making orderbooks and spectrum\\norder_books, df_spec = make_orderbooks(order_log, True)\\ndf_spec.to_csv('spectrum_singl.csv')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading\n",
    "\n",
    "from periods import PdfPeriod\n",
    "\n",
    "WORKING_DIR = \"/media/rufina/Seagate/DataMining/spectrums/2018-03/\"\n",
    "\n",
    "seccodes_new = []\n",
    "\n",
    "# find instruments that trade till 23:50\n",
    "for i in instruments_info:\n",
    "    if instruments_info[i]['SCHEDULE'] == 235000000000:\n",
    "        seccodes_new.append(i)\n",
    "        \n",
    "# print(seccodes_new)    --- ['USD000UTSTOM', 'EUR_RUB__TOM', 'EURUSD000TOM']\n",
    "\n",
    "output1 = {}             # store tables for first task - comparison by periods\n",
    "output2 = {}             # store tables for second task - comparison by days\n",
    "last_entry = {}          # store pdf for the previous day\n",
    "\n",
    "for sec in seccodes_new:\n",
    "    output1[sec] = [['Date', \"10:00 vs 15:00\", \"15:00 vs 19:00\", \"10:00 vs 19:00\"]]\n",
    "    output2[sec] = [['Date', \"10:00-15:00\", \"15:00-19:00\", \"19:00-23:50\"]]\n",
    "    last_entry[sec] = []\n",
    "    \n",
    "for spectrum_file in os.listdir(WORKING_DIR): # tradelog20180301_EURUSD000TOD.csv\n",
    "    secc = spectrum_file[17:-4]\n",
    "    date = spectrum_file[8:16]\n",
    "    if secc not in seccodes_new:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Proccesing. Date: {date}. Instrument: {secc}\\n\")\n",
    "        \n",
    "        # for output 1\n",
    "        df_spec = pd.read_csv(WORKING_DIR + spectrum_file)\n",
    "        current_pdf = PdfPeriod(seccode=secc)\n",
    "        current_pdf.calc_avgs(df_spec)\n",
    "        output1[secc].append(current_pdf.compare_by_periods(date))\n",
    "        \n",
    "        # for output 2\n",
    "        if len(last_entry[secc]) != 0: \n",
    "            output2[secc].append(current_pdf.compare_by_days(last_entry[secc], date))\n",
    "            last_entry[secc][0] = current_pdf.bids\n",
    "            last_entry[secc][1] = current_pdf.asks\n",
    "        else: \n",
    "            last_entry[secc].append(current_pdf.bids)\n",
    "            last_entry[secc].append(current_pdf.asks)\n",
    "            output2[secc].append([date, '-', '-', '-'])\n",
    "\n",
    "\n",
    "for i in output1:\n",
    "    pd.DataFrame(output1[i]).to_csv(i+'_output1.csv', index=False)\n",
    "    \n",
    "for i in output2:\n",
    "    pd.DataFrame(output2[i]).to_csv(i+'_output2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180301\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}